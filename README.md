# deepsee-live
Official landing page for DeepSeeâ„¢ â€“ the fully on-device AI content detector (images, videos, audio).  
No cloud. No data collection.

---

## ðŸŽ¥ Demo Video

Watch DeepSeeâ„¢ in action â€” cockpit verdicts, GUI walkthrough, and reproducible inference:

[â–¶ï¸ Watch on YouTube](https://youtu.be/ntOkek5MnxE)

This demo showcases:
- Real-time classification of AI vs legitimate images
- Binary verdict enforcement (`LIKELY AI` / `LIKELY LEGITIMATE`)
- GUI interface with audit-grade logging and reproducible results
- Privacy-first, on-device inference â€” no cloud, no data leakage

[â–¶ï¸ Launch Cockpit](https://github.com/JessiMarosi/deepsee-live/tree/main/cockpit)

---

## Mission

DeepSeeâ„¢ is designed to restore trust in digital content by offering reproducible, on-device forensic classification.  

Built by **Jessica S. Marosi**, Founder of ByteLockâ„¢, this cockpit enforces binary verdict logic, logs every decision, and operates without cloud dependencies â€” ensuring privacy, reproducibility, and audit-grade transparency.

---

## âœ… Cockpit Verdict Proof: Human vs AI Classification

DeepSeeâ„¢ runs fully on-device, classifying images with calibrated confidence and semantic analysis â€” no cloud, no data collection.  
The cockpit enforces strict verdict logic: only two outcomes are possible.

### Verdict Logic
- `THIS IMAGE IS LIKELY AI`
- `THIS IMAGE IS LIKELY LEGITIMATE`

No fallback strings. No ambiguity. Every verdict is logged and reproducible.

---

## ðŸ§ª Proof of Operation: Real Image Classification

| Input Image | Final Verdict | Confidence |
|-------------|----------------|------------|
| ![Likely AI](docs/proof_ai.jpg) | THIS IMAGE IS LIKELY AI | 98.61% |
| ![Likely Legitimate](docs/proof_legit.jpg) | THIS IMAGE IS LIKELY LEGITIMATE | 98.62% |

Each image was processed using:
- `classify_tflite.py` for raw model inference
- `deepsee_pipeline.py` for verdict enforcement
- `launch_gui.py` for cockpit display

All results are logged to `decisions.csv` and reproducible via CLI or GUI.  
Verdict logic is strictly binary: only `"THIS IMAGE IS LIKELY AI"` or `"THIS IMAGE IS LIKELY LEGITIMATE"` are possible.

---

## Cockpit: Forensic Classifier and Audit Trail

The `cockpit/` folder contains the operational pipeline behind DeepSeeâ„¢, designed for auditâ€‘grade AI content detection.

### Core Capabilities
- **Calibrated classification** using forensic features (EXIF, ELA, edge analysis) and semantic cues  
- **Strict verdict logic** â†’ only two possible outcomes  
- **Auditâ€‘grade logging** to SQLite (`deepsee_trainer.db`) with reproducible decision trails  
- **GUI interface** built with Gradio (`launch_gui.py`) for publicâ€‘facing demonstrations  
- **Fully reproducible, onâ€‘device inference** â€” no cloud dependencies, no data leakage  

---

## License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## Proof of Operation

DeepSeeâ„¢ cockpit has been tested with both AIâ€‘generated and legitimate images, producing consistent verdicts with >98% confidence.  
All results are logged to `decisions.csv` and reproducible via CLI or GUI.  
For detailed cockpit usage and recruiter contact, see [`cockpit/README.md`](cockpit/README.md).
